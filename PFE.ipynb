{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"tQfqiZmgE2Fr"},"outputs":[],"source":["import re\n","from matplotlib import matplotlib.pyplot as plt\n","from time import perf_counter\n","import json\n","import itertools\n","import ast\n","import pickle\n","import pandas as pd\n","from nltk.corpus import stopwords\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet\n","from pattern.en import pluralize, singularize\n","import enchant\n","import os\n","from deep_translator import (GoogleTranslator,\n","                             MicrosoftTranslator,\n","                             PonsTranslator,\n","                             LingueeTranslator,\n","                             MyMemoryTranslator,\n","                             YandexTranslator,\n","                             PapagoTranslator,\n","                             DeeplTranslator,\n","                             QcriTranslator,\n","                             single_detection,\n","                             batch_detection)\n","from utils import word_cloud,get_sentences,spellcheck,lookup,count_None,show_missing,lookup_set,avg_flavor\n","#nltk.download('wordnet')\n","\n","\n","p=WordNetLemmatizer()\n","d = enchant.Dict(\"en_GB\")\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RBSjeyS9E2Fy"},"source":["# Part 1\n","### this part contains\n","- extracting recipes from the text files\n","- text cleaning and removal of stopwords\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkZYXQaYE2F0"},"outputs":[],"source":["# extract the recipes alongside their names from each text file\n","\n","ingridient_list = get_sentences('dataset Cuisine Mag\\\\abats.txt','COMPOSITION.','\\d+\\.')\n","recipe_names = get_sentences('dataset Cuisine Mag\\\\abats.txt','\\d+\\.','COMPOSITION')\n","\n","# we repeat the same process for each seperate text file\n","for file in os.listdir('dataset Cuisine Mag'):\n","    if file.endswith('.txt'):\n","        print(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WkXkrfLLE2F1"},"outputs":[],"source":["\n","data = {'recipe_name':recipe_names, 'Ingredients':ingridient_list}\n","data2=pd.read_csv('FlavorDB\\\\flavor_db.csv')\n","df = pd.DataFrame(data)\n","\n","df['recipe_name']=df['recipe_name'].apply(lambda row:(row.split('\\n')))\n","df['Ingredients']=df['Ingredients'].str.lower()\n","df['Ingredients']=df.Ingredients.str.replace(r\"\\((\\s)?\\w+(\\s)?(\\w+(\\s)?)?\\*\\)\", ' ',regex=True) # removes (kerwiya *)\n","df['Ingredients']=df.Ingredients.str.replace(r\"tête d'(?=ail)\", ' ',regex=True) #\n","df['Ingredients']=df.Ingredients.str.replace(r\"\\s*\\(.*\\)\", '',regex=True)\n","df['Ingredients']=df.Ingredients.str.replace(r\"bien mûres|[^-œàéèçâêôa-zA-Z0-9']|\\bk?g (de)?\\b|l'|louche|gousses?|pour friture|hachée?|[0-9] ou [0-9]|[0-9] à [0-9]\", ' ',regex=True)\n","                                            #leaves french characters| removes kg and g| removes 4 ou 3 | removes 4 à 5\n","\n","df['Ingredients']=df.Ingredients.str.replace(r\"(?<!huile)d'(?!\\bolive\\b|youl|agneau|oiseaux)\",\" \",regex=True) #removes d' except for huile d'olive\n","\n","df['Ingredients']=df.Ingredients.str.replace(r\"(?<=sucre) semoule|glace|\\s*cristal(l)?isé|(mondées et)? moulues|entier|fraiches?|fonds|assez|quarantaine de|concassée|\\s*soup de|moulus|concassé|paquet de|mesure de|bien blanches|douzaine de|\\bfleur de\\b|viande\\s*(?=agneau)|pieds? de?|trempées|bottes? (de)?|bâtonnet de|côtelettes de|peu de|\\bviande de?\\b|tête|feuilles? de|tranche de|durs?|décortiquées|remplie de|concentré de|pointe de|\\s*pincées? de |variés|de préférence|\\bune?\\b|branches? de|rases? (de)?|facultatif|baguette de|quartier de|fort|rassis|tendres|sèches|poudre|râpé|sachet de|pulvérisé|bien remplie (de)?|fin(ement)?|bols? (de)?|litre (de)?|beaux|secs?|mises à tremper la veille|bottes? (de)?|feuilles? de (?!laurier)|\\bà\\s+huile\\b|tête (?=ail)|rond|entières|(Q|q)uelques|gouttes de|boite de|soupçon de|tiède|\\bun\\b|\\bà écosser\\b|fraiches|tasse d?e?|gross?e?s?|petite?s?|moyenn?e?s?|bon(ne)?|belles|frais|pilée?|measure de|noix de|verres? (de|à eau|à thé)? (de)?|(petit)? pied de|[0-9]+ (de)?|cuillèree?s? à \\w+ (de)?|cuillerée?s? (à \\w+ (de|d)?|(de)?)|poignées? (de)?|bouquets? de|trempés\\s?(ensemble)? la veille|environ (de)?|(en)? morceaux?|morceaux? de|livres? (de)?|un peu de|coupé|dés|\\ben\\b|rase \", ' ',regex=True)\n","\n","\n","df['Ingredients']=df['Ingredients'].str.lower() # lower case\n","\n","df['Ingredients_alpha']=df['Ingredients'].apply(lambda row:row.split('-')) #split into a list of words\n","\n","df['Ingredients_alpha']=df['Ingredients_alpha'].apply(lambda row:[w.lstrip(\" \") for w in row] ) # removing spaces\n","df['Ingredients_alpha']=df['Ingredients_alpha'].apply(lambda row:[w.lstrip() for w in row] )\n","df['Ingredients_alpha']=df['Ingredients_alpha'].apply(lambda row:[w.rstrip() for w in row] )\n","df['Ingredients_alpha']=df['Ingredients_alpha'].apply(lambda row:[w for w in row if w !='']) #remove empty words\n","df['Ingredients_alpha']=df['Ingredients_alpha'].apply(lambda row:[re.sub(r\"\\bou\\b.*\",'',w) for w in row] ) # removing second part of OR\n","df['Ingredients_alpha']=df['Ingredients_alpha'].apply(lambda row:[re.sub(r\"(?<=olives) .*\",'',w) for w in row] ) # removing the color of olives\n","df['Ingredients_alpha']=df['Ingredients_alpha'].apply(lambda row:[w.strip() for w in row] )\n","df['Ingredients_alpha'] = df['Ingredients_alpha'].apply(lambda row : list(set(row)))\n","df.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"UODXfvkDE2F2"},"outputs":[],"source":["word_cloud(df['Ingredients_alpha'])"]},{"cell_type":"markdown","metadata":{"id":"d1H2UUNNE2F3"},"source":["# Part 2\n","## this part contains\n","- replacing missing ingredients\n","- translation and spellchecking\n","- assigning each ingredient a set of molecules\n","- calculating average flavor sharing for both the savory and sweet dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BVOQu-VeE2F4"},"outputs":[],"source":["\n","\n","# we repeat the process for each pickle file ,you can just read all the pickle files and concatenate them into one big dataframe\n","\n","data= pd.read_pickle(r\"Pickle files/abats.pkl\")\n","\n","\n","# list of words that exist but causes issues due to translation error\n","troubled_words={'coquillettes':'macaroni','courges':'butternut squash','couscous':'couscous',\n","                'écorces  orange':'orange oil','écorces de citron':'lemon peel oil','haricots blancs':'kidney beans',\n","                'cardes':'cardoon','smen':'butter','veau':'beef','chapelure':'bread','eau de fleur  oranger':'neroli oil',\n","                'mouton':'mutton','fèves':'beans','vermicelles':'pasta','cubèbe':'pepper','colorant':'saffron','sardines':'clupeinae',\n","                'pois':'peas','piment':'capsicum','piment rouge   et fort':'capsicum','poissons':'fish','poivre noir':'white pepper',\n","                'poivre rouge':'pepper','huile':'cooking oil','farine':'flour','betteraves':'beetroot','courgettes':'green zucchini',\n","               'pigeons':'squab','pois cassés':'peas','mie de pain':'bread','pruneaux':'plum','haricots blancs à  œil noir':'black-eyed pea'}\n","\n","\n","#replacing composed items with the list of ingredient they include\n","replace_items={'hror':['poivre','cannelle','clou de girofle','coriandre','noix de muscade','gingembre','cardamome'],\n","              'viande séchée':['bœuf','huile','ail','carvi','poivre rouge','poivre noir', 'coriandre','cumin','sel'],\n","              'dersa':['ail','cannelle','cumin','piment','sel','laurier'],\n","              'ras lhanout':['cumin','gingembre','sel','poivre','cannelle','coriandre','allspice','clove','piment'],\n","              'chermoula':['oignon','ail','persil','poivre rouge','cumin','poivre noir','citron','farine','sel','huile'],\n","              'crêpes':['semouline','farine','sel','eau'],\n","               'tlitli':['semouline','sel','eau'],\n","               \"d'youl\":['semouline','farine','sel','water'],\n","              'plombs':['semoule','semouline','sel'],\n","              'tous les légumes de la saison':['pomme de terre','carotte', 'navet', 'courgettes','poireau']}\n","#the replacement process\n","for i,ls in data.iterrows():\n","    expansions = (replace_items[e] if e.lower() in replace_items.keys() else [e] for e in ls['Ingredients_alpha'])\n","    expanded=[v for vals in expansions for v in vals]\n","    data.at[i,'Ingredients_alpha']=expanded\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLQOBZYLE2F6"},"outputs":[],"source":["\n","#turning the list of ingredients into  dictionaries\n","data['Ingredients_alpha'] = data.Ingredients_alpha.apply(lambda x: ast.literal_eval(str(x)))\n","data['Ingredients_alpha'] = data.Ingredients_alpha.apply(lambda x:dict.fromkeys(x, \"\"))\n","for  element in data['Ingredients_alpha']:\n","    for k,v in element.items():\n","        #check each ingredient\n","        if k.strip() in troubled_words.keys():\n","            #if the word exists in troubled_words , replace it directly\n","            words=troubled_words[k.strip()]\n","        else:\n","            #else translate it and make it lower case\n","            translated = GoogleTranslator(source='fr', target='en').translate(text=k).lower()\n","            #spell check if the word exists in an english dictionary\n","            words=spellcheck(translated.split(' '),data2)\n","        element[k]=lookup(words,data2)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDeL1fdtE2F8"},"outputs":[],"source":["# sanity check\n","count_None(data['Ingredients_alpha'])"]},{"cell_type":"markdown","metadata":{"id":"T0Qxsb1tE2F9"},"source":["## Average food sharing calculation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wc7LNhiLE2F9","outputId":"22d50bb1-de36-4c88-eca4-94cfcc275e9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["35.92777107479222\n"]}],"source":["# after repeating the process for all the clean pickle files , concatenate them into one dataframe\n","data_food=pd.read_csv('data_food_final.csv')\n","\n","##create a dictionary of english ingredients\n","ls=[]\n","for element in data_food['eng_Ingredients_alpha']:\n","    element=ast.literal_eval(element)\n","    z=[]\n","\n","    for k,v in (element).items():\n","        z.append(k)\n","\n","    ls.append(z)\n","\n","data_food['Ingredients_molecules']=ls\n","data_food['Ingredients_molecules']=data_food.Ingredients_molecules.apply(lambda x:dict.fromkeys(x, \"\"))\n","\n","# find the molecular set for each ingredient\n","for element in data_food['Ingredients_molecules']:\n","    for k,v in element.items():\n","        element[k]=lookup_set(k,data2)\n","\n","#calculate average flavor sharing\n","data_food['avg_flavor']=data_food['Ingredients_molecules'].apply(lambda x:avg_flavor(x))\n","final_score=sum(data_food['avg_flavor'])/data_food['avg_flavor'].shape[0]\n","print(final_score)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"er0hmqOCE2F-","outputId":"2dc7c156-7fbf-4337-d0d6-de72c5140ba1"},"outputs":[{"name":"stdout","output_type":"stream","text":["14.469971139971143\n"]}],"source":["#repeat the same process for sweet recipes\n","data_gat=pd.read_csv('data_gateaux.csv')\n","\n","\n","#drop this recipe because it only contains one ingredient\n","data_gat=data_gat.drop(79,axis=0)\n","\n","# create a dictionary of english ingredients\n","ls=[]\n","for element in data_gat['eng_Ingredients_alpha']:\n","    element=ast.literal_eval(element)\n","    z=[]\n","    for k,v in element.items():\n","        z.append(k)\n","\n","    ls.append(z)\n","data_gat['Ingredients_molecules']=ls\n","data_gat['Ingredients_molecules']=data_gat.Ingredients_molecules.apply(lambda x:dict.fromkeys(x, \"\"))\n","\n","\n","for element in data_gat['Ingredients_molecules']:\n","    for k,v in element.items():\n","        element[k]=lookup_set(k,data2)\n","data_gat['avg_flavor']=data_gat['Ingredients_molecules'].apply(lambda x:avg_flavor(x))\n","final_score=sum(data_gat['avg_flavor'])/data_gat['avg_flavor'].shape[0]\n","print(final_score)\n",""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"56be9ae5b7276ece4bebe2a9b69e84662161f8cf62f76c0defc86d97a72f7241"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}